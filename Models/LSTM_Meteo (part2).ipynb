{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install tensorflow\n",
    "# !pip install setuptools\n",
    "# !pip install keras\n",
    "# !pip install keras-tuner\n",
    "# !pip install seaborn\n",
    "# !pip install matplotlib\n",
    "# !pip install scikit-learn\n",
    "# !pip install scipy\n",
    "# !pip install statsmodels\n",
    "# !pip install pvlib\n",
    "# !pip install xgboost\n",
    "# !pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, BatchNormalization, Conv1D, MaxPooling1D, Reshape, GRU, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from keras.losses import  MeanSquaredError, MeanAbsoluteError, MeanSquaredLogarithmicError\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_log_error, mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import pvlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Довжину вхідної послідовності для LSTM\n",
    "sequence_length = 4\n",
    "\n",
    "# Кількість часових кроків на виході LSTM\n",
    "forecast_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отримання даних по станції за період\n",
    "def get_data(_station_name, _power_max, _date_start, _date_end, _meteo_source = 'OpenMeteo', _actual_source = 'Nordik'):\n",
    "\n",
    "    # Завантаження даних\n",
    "    df_meteo = pd.read_csv(f'../data/{_station_name}_{_meteo_source}_Data.csv', sep=',', comment='#')\n",
    "    df_meteo['datetime'] = pd.to_datetime(df_meteo['datetime'], format='mixed', utc=True)\n",
    "\n",
    "    actual_parameters=['datetime', 'power', 'limitation']\n",
    "    df_actual = pd.read_csv(f'../data/{_station_name}_{_actual_source}_Data.csv', sep=',', comment='#', usecols=actual_parameters)\n",
    "    df_actual['datetime'] = pd.to_datetime(df_actual['datetime'], format='mixed', utc=True)\n",
    "\n",
    "    # Злиття датафреймів\n",
    "    data_input = pd.DataFrame()\n",
    "    data_input = pd.merge(df_actual, df_meteo, on='datetime', how='outer', suffixes=('_actual', '_predict'))\n",
    "\n",
    "    # Перевірка на однакові колонки\n",
    "    for col in df_actual.columns:\n",
    "        if col in df_meteo.columns and col not in ['datetime']:\n",
    "            # Якщо є однакові колонки то залишити з df_actual \n",
    "            data_input[col] = data_input[f\"{col}_actual\"].combine_first(data_input[f\"{col}_predict\"])\n",
    "            data_input.drop(columns=[f\"{col}_predict\", f\"{col}_actual\"], inplace=True)\n",
    "\n",
    "    # Збереження необхідних колонок\n",
    "    data_input.columns = [col.replace('_actual', '') for col in data_input.columns]\n",
    "    data_input = data_input[df_actual.columns.tolist() + [col for col in df_meteo.columns if col not in df_actual.columns and col != 'datetime']]\n",
    "\n",
    "    add_time_transofrm(data_input, _tranform_hours = True, _transform_days = True)\n",
    "    data_input.set_index('datetime', inplace=True)\n",
    "\n",
    "    # Фільтрація даних за датою\n",
    "    if _date_start is not None and _date_end is not None:\n",
    "        _data = data_input.loc[_date_start:_date_end].copy()\n",
    "    elif _date_start is not None:\n",
    "        _data = data_input.loc[_date_start:].copy()\n",
    "    elif _date_end is not None:\n",
    "        _data = data_input.loc[:_date_end].copy()\n",
    "    else:\n",
    "        _data = data_input.copy()\n",
    "\n",
    "    # Видалення невалідних записів\n",
    "    if 'limitation' in _data.columns:\n",
    "        _data = _data[_data['limitation'] == 0]\n",
    "        _data.drop(columns=['limitation'], inplace=True)\n",
    "    \n",
    "    # Видалення пропущених значень\n",
    "    _data.dropna(inplace=True)\n",
    "    \n",
    "    # Обмеження значень потужності\n",
    "    _data.clip(lower=0, upper=_power_max, inplace=True)\n",
    "\n",
    "    return _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Представлення кодів погоди у вагових коефіцієнтах\n",
    "def add_weather_codes(data):\n",
    "    \n",
    "    # Мапінг кодів у вагові коефіцієнти\n",
    "    weather_code_mapping = {\n",
    "        \n",
    "        # Мінімальний вплив\n",
    "        0: 0.2,\n",
    "\n",
    "        # Середній вплив\n",
    "        1: 0.5, 2: 0.5, 3: 0.5,\n",
    "        51: 0.5, 53: 0.5, 55: 0.5,\n",
    "        \n",
    "        # Сильний вплив\n",
    "        45: 0.8, 48: 0.8,\n",
    "        56: 0.8, 57: 0.8,\n",
    "        \n",
    "        # Критичний вплив\n",
    "        61: 1.0, 63: 1.0, 65: 1.0,\n",
    "        66: 1.0, 67: 1.0,\n",
    "        71: 1.0, 73: 1.0, 75: 1.0,\n",
    "        77: 1.0,\n",
    "        80: 1.0, 81: 1.0, 82: 1.0,\n",
    "        85: 1.0, 86: 1.0,\n",
    "        95: 1.0,\n",
    "        96: 1.0, 99: 1.0\n",
    "    }\n",
    "\n",
    "    weather_code_column = 'weather_code'\n",
    "    if weather_code_column in data.columns:\n",
    "        data['weather_conditions'] = data[weather_code_column].map(weather_code_mapping)\n",
    "        data.drop(columns=[weather_code_column], inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_solarposition(_data, _latitude, _longitude, _altitude=350):\n",
    "\n",
    "    # Отримуємо сонячну позицію для всіх рядків\n",
    "    solar_positions = pvlib.solarposition.get_solarposition(\n",
    "        time=_data.index,\n",
    "        latitude=_latitude,\n",
    "        longitude=_longitude,\n",
    "        altitude=_altitude\n",
    "    )\n",
    "    # https://pvlib-python.readthedocs.io/en/v0.4.2/api.html\n",
    "    \n",
    "    _data['apparent_elevation'] = solar_positions['apparent_elevation'].clip(lower=0)\n",
    "    _data['solar_azimuth'] = solar_positions['azimuth']\n",
    "    _data['is_night'] = _data['apparent_elevation'] <= 0\n",
    "    \n",
    "    return _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_forecast_0(_data, columns_list = ['gti', 'ghi', 'dni']):\n",
    "\n",
    "    # Перевірка на порожній DataFrame\n",
    "    if _data.empty:\n",
    "        print(\"Вхідний DataFrame _data порожній.\")\n",
    "        return _data\n",
    "    \n",
    "    # Вибірка даних\n",
    "    columns = [col for col in columns_list if col in _data.columns]\n",
    "    \n",
    "    if not columns:\n",
    "        print(\"Жодна з колонок у columns_list не знайдена в _data.\")\n",
    "        return _data\n",
    "    \n",
    "    X = _data[columns]\n",
    "    if X.empty:\n",
    "        print(\"Відфільтрований DataFrame X порожній.\")\n",
    "        return _data\n",
    "    \n",
    "    if 'power' not in _data.columns:\n",
    "        print(\"Колонка 'power' відсутня в _data.\")\n",
    "        return _data\n",
    "    \n",
    "    y = _data['power']\n",
    "\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X, y)\n",
    "\n",
    "    # Прогнозування\n",
    "    y_pred = reg.predict(X)\n",
    "    _data['forecast_0'] = y_pred\n",
    "    _data.loc[:, 'forecast_0'] = _data['forecast_0'].clip(lower=0)\n",
    "\n",
    "    return _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cинусоїдальні та косинусоїдальні перетворення часу для моделювання циклічності часу (доба і рік)\n",
    "def add_time_transofrm(_data, _tranform_hours = True, _transform_days = True):\n",
    "\n",
    "    # Трансформація годин\n",
    "    if _tranform_hours:\n",
    "        _data[\"minute\"] = _data[\"datetime\"].dt.minute\n",
    "        _data[\"hour\"] = _data[\"datetime\"].dt.hour\n",
    "        _data[\"total_minutes\"] = _data[\"hour\"] * 60 + _data[\"minute\"]\n",
    "    \n",
    "        peak_shift = 780 + 3 * 60\n",
    "        _data[\"adjusted_minutes\"] = (\n",
    "            _data[\"total_minutes\"] - peak_shift) % 1440\n",
    "\n",
    "        # Застосування синусоїдальних і косинусоїдальних перетворень до годин\n",
    "        _data[\"hour_sin\"] = np.sin(\n",
    "            2 * np.pi * _data[\"adjusted_minutes\"] / 1440)\n",
    "        _data[\"hour_cos\"] = np.cos(\n",
    "            2 * np.pi * _data[\"adjusted_minutes\"] / 1440)\n",
    "        \n",
    "        _data.drop(columns=[\"minute\",\"hour\",\"total_minutes\",\"adjusted_minutes\"],errors=\"ignore\",inplace=True,)\n",
    "\n",
    "    # Трансформація дня року\n",
    "    if _transform_days:\n",
    "        _data[\"day\"] = _data[\"datetime\"].dt.dayofyear\n",
    "        peak_shift_day = 173\n",
    "\n",
    "        _data[\"adjusted_day\"] = (_data[\"day\"] - peak_shift_day) % 365\n",
    "\n",
    "        # Застосування синусоїдальних і косинусоїдальних перетворень до днів року\n",
    "        _data[\"day_sin\"] = np.sin(2 * np.pi * _data[\"adjusted_day\"] / 365)\n",
    "        _data['day_cos'] = np.cos(\n",
    "            2 * np.pi * _data['adjusted_day'] / 365 / 2.)\n",
    "\n",
    "        _data.drop(columns=[\"day\",\"adjusted_day\",],errors=\"ignore\",inplace=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Додавання лагів для вибраних ознак\n",
    "def add_lag_features(_data, lagged_features, lags):\n",
    "    \n",
    "    new_features = lagged_features.copy()\n",
    "\n",
    "    for feature in lagged_features:\n",
    "        for lag in range(1, lags + 1):\n",
    "            lag_col = f'{feature}_lag_{lag}'\n",
    "            _data[lag_col] = _data[feature].shift(lag)\n",
    "            new_features.append(lag_col)\n",
    "\n",
    "    # Видалення рядків з порожніми значеннями після додавання лагів\n",
    "    _data.dropna(subset=new_features, inplace=True)\n",
    "    return _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Додаткові ознаки\n",
    "def add_features(_data, _latitude, _longitude, _altitude, _meteo_source):\n",
    "\n",
    "    # Розрахунок висоти сонця\n",
    "    add_solarposition(_data, _latitude, _longitude, _altitude)\n",
    "\n",
    "    # Обробка кодів погоди\n",
    "    add_weather_codes(_data)\n",
    "\n",
    "    # Розрахунок прогнозної потужності Linear Regression\n",
    "    meteo_parameters_dict = {\n",
    "        'Nordik': ['ghi', 'temperature_pv'],\n",
    "        'Copernicus': ['toa', 'ghi', 'bhi', 'dhi', 'bni'],\n",
    "        'OpenMeteo': ['gti', 'ghi', 'dni'],\n",
    "    }\n",
    "    meteo_parameters = meteo_parameters_dict.get(_meteo_source, ['ghi'])\n",
    "    add_forecast_0(_data, columns_list=meteo_parameters)\n",
    "\n",
    "    add_lag_features(_data, meteo_parameters, 3)\n",
    "\n",
    "    return _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Підготовка даних для моделі\n",
    "def prepare_data(_data, _scaler, _power_max, _split_ratio=0.8, use_all_features = False):\n",
    "\n",
    "    # Вибрані ознаки\n",
    "    if use_all_features:\n",
    "        feature_columns = [col for col in _data.columns if col != \"power\"]\n",
    "    else:\n",
    "        feature_columns = ['forecast_0', 'gti', 'temperature_air', 'temperature_pv', 'humidity', 'apparent_elevation', 'is_night', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
    "        feature_columns += [col for col in _data.columns if '_lag_' in col]\n",
    "    feature_columns = [col for col in feature_columns if col in _data.columns]\n",
    "\n",
    "    # Цільова змінна\n",
    "    target_column = 'power'    \n",
    "\n",
    "    # Вибірка даних для моделі\n",
    "    # Перша колонка - цільова змінна power, інші - ознаки\n",
    "    _data = _data[[target_column] + feature_columns]\n",
    "\n",
    "    # Розділення даних на навчальну та тестову вибірки\n",
    "    if _split_ratio != 0:\n",
    "        split_index = int(len(_data) * _split_ratio)\n",
    "        data_train = _data.iloc[:split_index]\n",
    "        data_test = _data.iloc[split_index:]\n",
    "    else:\n",
    "        data_train = _data\n",
    "        data_test = _data\n",
    "\n",
    "    # Масштабування даних\n",
    "    data_train_scaled = _scaler.fit_transform(data_train)\n",
    "    data_test_scaled = _scaler.transform(data_test)\n",
    "\n",
    "    def prepare_sequences(scaled_data, original_data, sequence_length, forecast_steps):\n",
    "        X, y, datetimes = [], [], []\n",
    "        for i in range(sequence_length, len(scaled_data) - forecast_steps + 1):\n",
    "            y.append(scaled_data[i:i+forecast_steps, 0])    # цільова змінна power\n",
    "            X.append(scaled_data[i-sequence_length:i, 1:])  # ознаки\n",
    "            datetimes.append(original_data.index[i+forecast_steps-1])\n",
    "        return np.array(X), np.array(y), datetimes\n",
    "\n",
    "    X_train, y_train, datetimes_train = prepare_sequences(data_train_scaled, data_train, sequence_length, forecast_steps)\n",
    "\n",
    "    X_test, y_test, datetimes_test = prepare_sequences(data_test_scaled, data_test, sequence_length, forecast_steps)\n",
    "\n",
    "    print(f\"\\nРозмір навчальної вибірки: {len(X_train)}\")\n",
    "    print(f\"Розмір тестової вибірки: {len(X_test)}\")\n",
    "    print(f\"Ознаки ({len(feature_columns)}): {feature_columns}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, datetimes_train, datetimes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_data(_scaler, _forecast, _X_test, _y_test, _datetimes_test):\n",
    "\n",
    "    # Визначення кількості колонок у масштабованих даних\n",
    "    n_features = _scaler.n_features_in_\n",
    "\n",
    "    # Перевірка узгодженості розмірів\n",
    "    if len(_forecast) != len(_y_test) or len(_datetimes_test) != len(_forecast):\n",
    "        raise ValueError(\"Розміри _forecast, _y_test і _datetimes_test не збігаються.\")\n",
    "\n",
    "    # Відновлення масштабу для тестових даних\n",
    "    y_test_rescaled = _scaler.inverse_transform(\n",
    "        np.c_[_y_test[:, 0], np.zeros((_y_test.shape[0], n_features - 1))]\n",
    "    )[:, 0]\n",
    "\n",
    "    # Відновлення масштабу для прогнозу\n",
    "    forecast_rescaled = _scaler.inverse_transform(\n",
    "        np.c_[_forecast[:, 0], np.zeros((_forecast.shape[0], n_features - 1))]\n",
    "    )[:, 0]\n",
    "\n",
    "    # Створення DataFrame з відновленими даними\n",
    "    data_forecast = pd.DataFrame({\n",
    "        \"datetime\": _datetimes_test,\n",
    "        \"power\": y_test_rescaled,\n",
    "        \"forecast\": forecast_rescaled\n",
    "    })\n",
    "\n",
    "    # Сортування за датою (необов'язково, якщо дані вже впорядковані)\n",
    "    data_forecast.sort_values('datetime', inplace=True)\n",
    "\n",
    "    return data_forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_forecast(_data_forecast, _data):\n",
    "    \n",
    "    _data_forecast.loc[:, 'forecast'] = _data_forecast['forecast'].clip(lower=0)\n",
    "\n",
    "    _data_forecast = _data_forecast.merge(_data, on='datetime', how='left', suffixes=('', '_train'))\n",
    "\n",
    "    if 'forecast_0' in _data_forecast.columns:\n",
    "        _data_forecast.loc[(_data_forecast['forecast_0'] == 0) | (_data_forecast['is_night'] == 1), 'forecast'] = 0\n",
    "\n",
    "    return _data_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Графік відносних залишків\n",
    "def plot_residuals(_y_train_actual=None, _y_train_forecast=None, _y_test_actual=None, _y_test_forecast=None, _power_max=0, _title=\"Графік відносних залишків\"):\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    # Автоматичне визначення power_max, якщо він не заданий\n",
    "    if _power_max == 0:\n",
    "        max_train = max(_y_train_actual) if _y_train_actual is not None else 0\n",
    "        max_test = max(_y_test_actual) if _y_test_actual is not None else 0\n",
    "        _power_max = max(max_train, max_test)\n",
    "        _power_max = max(_power_max, 1)\n",
    "        \n",
    "    # Перевірка та побудова графіка для навчальних даних\n",
    "    if _y_train_actual is not None and _y_train_forecast is not None:\n",
    "        train_residuals = (_y_train_actual - _y_train_forecast) / _power_max\n",
    "        plt.scatter(_y_train_forecast, train_residuals, alpha=0.5, color='#87CEEB', marker='o', label='Навчальні дані')\n",
    "\n",
    "    # Перевірка та побудова графіка для тестових даних\n",
    "    if _y_test_actual is not None and _y_test_forecast is not None:\n",
    "        test_residuals = (_y_test_actual - _y_test_forecast) / _power_max\n",
    "        plt.scatter(_y_test_forecast, test_residuals, alpha=0.5, color='#FFD700', marker='s', label='Тестові дані')\n",
    "\n",
    "    # Лінія нульових залишків\n",
    "    plt.axhline(0, color='black', linewidth=2, linestyle='--', label='Лінія 0 залишків')\n",
    "\n",
    "    plt.xlabel('Прогнози, кВт')\n",
    "    plt.ylabel('Відносні залишки')\n",
    "    plt.title(_title)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residual_histogram(_y_actual, _y_forecast, _bins=30, _power_max=0, _title=\"Гістограма залишків\"):\n",
    "\n",
    "    # Автоматичне визначення power_max, якщо він не заданий\n",
    "    if _power_max == 0:\n",
    "        max_train = max(_y_actual) if _y_actual is not None else 0\n",
    "        _power_max = max(max_train, 1)\n",
    "\n",
    "    # Розрахунок залишків\n",
    "    residuals = ( _y_actual - _y_forecast ) / _power_max\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.hist(residuals, bins=_bins, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "    plt.title(_title)\n",
    "    plt.xlabel(\"Залишки\")\n",
    "    plt.ylabel(\"Частота\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Відображення кривих навчання\n",
    "def plot_loss(_history, _title='Криві навчання', _metrics=['loss']):\n",
    "\n",
    "    for metric in _metrics:\n",
    "        plt.figure(figsize=(5, 3))\n",
    "        plt.plot(_history.history[metric], label=f'{metric} на тренуванні')\n",
    "        plt.plot(_history.history[f'val_{metric}'], label=f'{metric} на перевірці')\n",
    "        plt.xlabel('епохи')\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(f'{_title} - {metric}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Відображення часових рядів\n",
    "def plot_series(_data, _columns, _title=\"Фактична і Прогнозована потужність\", _metrics=None, _split_days=0):\n",
    "\n",
    "    # Дата-час може бути в індексі або в колонці \"datetime\"\n",
    "    if \"datetime\" in _data.columns:\n",
    "        datetime_col = _data[\"datetime\"]\n",
    "    else:\n",
    "        datetime_col = _data.index\n",
    "\n",
    "    start_index = 0\n",
    "    end_index = len(_data)\n",
    "    data_plot = _data.iloc[start_index:end_index].copy()\n",
    "    datetime_col_plot = datetime_col[start_index:end_index]\n",
    "\n",
    "    # Візуалізація графіків\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for col in _columns:\n",
    "        plt.plot(datetime_col_plot, data_plot[col[\"column\"]], label=col[\"label\"])\n",
    "    plt.title(f\"{_title}\")\n",
    "    \n",
    "    # Візуалізація метрик\n",
    "    metrics_text = \"\"\n",
    "    if _metrics is not None:\n",
    "        metrics_text = \"\\n\".join([\n",
    "            f'APE = {_metrics[\"APE\"]:.1f}%',\n",
    "            f'MAPE(max) = {_metrics[\"MAPE(max)\"]:.1f}%',\n",
    "            f'MAPE(max) = {_metrics[\"MAPE(max)\"]:.1f}%',            \n",
    "            f'R2 = {_metrics[\"R2\"]:.3f}',\n",
    "            f'MSLE = {_metrics[\"MSLE\"]:.3f}',\n",
    "            f'Bias = {_metrics[\"Bias\"]:.1f}',\n",
    "            # f'APE = {_metrics[\"APE\"]:.2f}%',\n",
    "            # f'sMAPE = {_metrics[\"MAPE\"]:.1e}',\n",
    "            # f'EV = {_metrics[\"EV\"]:.3f}',\n",
    "            # f'PCC = {_metrics[\"PCC\"]:.3f}'\n",
    "        ])\n",
    "        \n",
    "    plt.legend(loc='upper left', title=metrics_text)\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Візуалізація графіків по частинах\n",
    "    if _split_days > 0:\n",
    "        data_len = len(_data)\n",
    "        days_in_step = _split_days * 24 * 4\n",
    "        for i in range(0, data_len, days_in_step):\n",
    "            data_chunk = _data.iloc[i:i + days_in_step]\n",
    "            datetime_chunk = datetime_col.iloc[i:i + days_in_step]\n",
    "\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            for col in _columns:\n",
    "                plt.plot(datetime_chunk, data_chunk[col[\"column\"]], label=col[\"label\"])\n",
    "            plt.title(f\"{_title} - Інтервал {i // days_in_step + 1}\")\n",
    "            plt.legend(loc='upper left')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Завантаження моделі з файлу\n",
    "def get_model(_model_name):\n",
    "    \n",
    "    model = load_model(f\"../temp/{_model_name}.keras\")\n",
    "    scaler = np.load(f\"../temp/{_model_name}.npy\", allow_pickle=True).item()\n",
    "    \n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Побудова моделі\n",
    "def create_model(X_train):\n",
    "\n",
    "    # Побудова моделі\n",
    "    layer_params = [\n",
    "        {\n",
    "            \"units\": 128,\n",
    "            \"activation\": \"tanh\",\n",
    "            \"dropout\": 0.1,\n",
    "            \"regularizer\": l2(0.01)\n",
    "        },\n",
    "        {\n",
    "            \"units\": 256,\n",
    "            \"activation\": \"relu\",\n",
    "            \"dropout\": 0.1,\n",
    "            \"regularizer\": l2(0.01)\n",
    "        },\n",
    "        {\n",
    "            \"units\": 128,\n",
    "            \"activation\": \"elu\",\n",
    "            \"dropout\": 0.1,\n",
    "            \"regularizer\": l2(0.01)\n",
    "        },\n",
    "    ]\n",
    "    model_lstm = Sequential([\n",
    "        Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        LSTM(\n",
    "            units=layer_params[0][\"units\"],\n",
    "            activation=layer_params[0][\"activation\"],\n",
    "            return_sequences=True,\n",
    "            kernel_regularizer=layer_params[0][\"regularizer\"],\n",
    "        ),\n",
    "        Dropout(layer_params[0][\"dropout\"]),\n",
    "        BatchNormalization(),\n",
    "        LSTM(\n",
    "            units=layer_params[1][\"units\"],\n",
    "            activation=layer_params[1][\"activation\"],\n",
    "            return_sequences=True,\n",
    "            kernel_regularizer=layer_params[1][\"regularizer\"],\n",
    "        ),\n",
    "        Dropout(layer_params[1][\"dropout\"]),\n",
    "        BatchNormalization(),\n",
    "        LSTM(\n",
    "            units=layer_params[2][\"units\"],\n",
    "            activation=layer_params[2][\"activation\"],\n",
    "            return_sequences=True,\n",
    "            kernel_regularizer=layer_params[2][\"regularizer\"],\n",
    "        ),\n",
    "        Dropout(layer_params[2][\"dropout\"]),\n",
    "        BatchNormalization(), \n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dense(forecast_steps)\n",
    "    ])\n",
    "    # Компіляція моделі\n",
    "    model_lstm.compile(optimizer='nadam', loss=[MeanSquaredError()])\n",
    "    # MeanSquaredLogarithmicError, MeanSquaredError, MeanAbsoluteError\n",
    "\n",
    "    return model_lstm\n",
    "\n",
    "    # model_lstm = Sequential([\n",
    "    #     Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    #     LSTM(50, return_sequences=False),\n",
    "    #     Dense(forecast_steps)\n",
    "    # ])\n",
    "    # # Компіляція моделі\n",
    "    # model_lstm.compile(optimizer='adam', loss='mse')    \n",
    "    # return model_lstm\n",
    "\n",
    "    # model_lstm = Sequential([\n",
    "    #     Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    #     Bidirectional(LSTM(64, return_sequences=True)),  # Бінаправлений LSTM з 64 нейронами\n",
    "    #     Bidirectional(LSTM(32)),  # Бінаправлений LSTM з 32 нейронами\n",
    "    #     Dense(32, activation='relu'),  # Повнозв'язний шар\n",
    "    #     Dense(1, activation='sigmoid')  # Вихідний шар для задачі класифікації (1/0)\n",
    "    # ])\n",
    "    # # Компіляція моделі\n",
    "    # model_lstm.compile(optimizer='adam', loss='mse')    \n",
    "    # return model_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Збереження моделі в файлі\n",
    "def save_model(_model, _scaler, _model_name):\n",
    "\n",
    "    path = \"../temp/\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    _model.save(f\"{path}{_model_name}.keras\")\n",
    "    np.save(f\"../temp/{_model_name}.npy\", _scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тренування моделі\n",
    "def do_train(_model, _X_train, _X_test, y_train, y_test):\n",
    "\n",
    "    history = _model.fit(\n",
    "        _X_train, y_train,\n",
    "        validation_data=(_X_test, y_test),\n",
    "        epochs=32,\n",
    "        batch_size=64,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],\n",
    "        verbose=1\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Розрахунок метрик\n",
    "def evaluate_data(_forecast, _actual, _power_max=0, _print_metrics=False):\n",
    "\n",
    "        # _actual = np.where(_actual == 0, 1e-8, _actual)\n",
    "    \n",
    "        if _power_max == 0:\n",
    "            _power_max = np.max(_actual)\n",
    "\n",
    "        tae = np.sum(np.abs(_forecast - _actual))\n",
    "\n",
    "        mae = mean_absolute_error(_actual, _forecast)\n",
    "        mae_max = (mae / _power_max) * 100\n",
    "\n",
    "        mape = mean_absolute_percentage_error(_actual, _forecast) * 100\n",
    "        mape_max = np.mean(np.abs((_forecast - _actual) / _power_max)) * 100  \n",
    "\n",
    "        def symmetric_mean_absolute_percentage_error(actual, forecast):\n",
    "            numerator = np.abs(actual - forecast)\n",
    "            denominator = (np.abs(actual) + np.abs(forecast)) / 2\n",
    "            smape = np.mean(numerator / denominator) * 100\n",
    "            return smape\n",
    "        smape = symmetric_mean_absolute_percentage_error(_actual, _forecast)\n",
    "\n",
    "        mse = mean_squared_error(_actual, _forecast)\n",
    "\n",
    "        rmse = np.sqrt(mse)\n",
    "        rmse_max = np.sqrt(mse) / _power_max * 100\n",
    "\n",
    "        r2 = r2_score(_actual, _forecast)\n",
    "        ev = explained_variance_score(_actual, _forecast)\n",
    "\n",
    "        bias = np.mean(_forecast - _actual) / _power_max * 100\n",
    "\n",
    "        msle = mean_squared_log_error(_actual - np.min(_actual) + 1,\n",
    "                                      _forecast - np.min(_forecast) + 1)\n",
    "        try:\n",
    "            pcc, _ = pearsonr(_actual - np.min(_actual) + 1,\n",
    "                              _forecast - np.min(_forecast) + 1)\n",
    "        except ValueError: pcc = np.nan\n",
    "\n",
    "        metrics = {\n",
    "            \"TAE\": tae,\n",
    "            \"MAE\": mae,\n",
    "            \"MAPE(max)\": mape_max,            \n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"RMSE(max)\": rmse_max,\n",
    "            \"R2\": r2,\n",
    "            \"MSLE\": msle,\n",
    "            \"Bias\": bias,\n",
    "            \"EV\": ev,\n",
    "            \"PCC\": pcc\n",
    "        }\n",
    "\n",
    "        if _print_metrics:\n",
    "            for key, value in metrics.items():\n",
    "                print(f\"{key}: {value:.3f}\")\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прогнозування\n",
    "def do_forecast(_model, _X, batch_size=None, verbose=0):\n",
    "\n",
    "    try:\n",
    "        # Перевірка моделі та даних\n",
    "        if _model is None or not hasattr(_model, 'predict'):\n",
    "            raise ValueError(\"Передана модель не має методу 'predict' або не задана.\")\n",
    "        if _X is None or not isinstance(_X, np.ndarray):\n",
    "            raise ValueError(\"Передані вхідні дані повинні бути масивом numpy (np.ndarray).\")\n",
    "\n",
    "        # Прогнозування\n",
    "        forecast = _model.predict(_X, batch_size=batch_size, verbose=verbose)\n",
    "        return forecast\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Помилка під час прогнозування: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Навчання та прогнозування"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lstm_model'\n",
    "\n",
    "models_list = [\n",
    "    {\n",
    "        \"station_name\": 'Yavoriv',\n",
    "        \"meteo_source\": 'OpenMeteo',\n",
    "        \"power_max\": 59234,\n",
    "        \"latitude\": 49.935239,\n",
    "        \"longitude\": 23.505527,\n",
    "        \"altitude\": 270,\n",
    "        \"date_train_start\": '2024-04-02',\n",
    "        \"date_train_end\": '2024-09-15'\n",
    "    },\n",
    "    {\n",
    "        \"station_name\": 'Glyniany-1',\n",
    "        \"meteo_source\": 'OpenMeteo',\n",
    "        \"power_max\": 2976,\n",
    "        \"latitude\": 49.826009,\n",
    "        \"longitude\": 24.476087,\n",
    "        \"altitude\": 310,\n",
    "        \"date_train_start\": '2024-04-02',\n",
    "        \"date_train_end\": '2024-09-15'\n",
    "    },\n",
    "    {\n",
    "        \"station_name\": 'Glyniany-2',\n",
    "        \"meteo_source\": 'OpenMeteo',\n",
    "        \"power_max\": 15442,\n",
    "        \"latitude\": 49.826411,\n",
    "        \"longitude\": 24.488083,\n",
    "        \"altitude\": 310,\n",
    "        \"altitude\": 350,\n",
    "        \"date_train_start\": '2024-04-02',\n",
    "        \"date_train_end\": '2024-09-15'\n",
    "    },\n",
    "    {\n",
    "        \"station_name\": 'Boryslav',\n",
    "        \"meteo_source\": 'OpenMeteo',\n",
    "        \"power_max\": 7153,\n",
    "        \"latitude\": 49.308290,\n",
    "        \"longitude\": 23.430082,\n",
    "        \"altitude\": 350,\n",
    "        \"date_train_start\": '2024-04-02',\n",
    "        \"date_train_end\": '2024-09-15'\n",
    "    },\n",
    "    {\n",
    "        \"station_name\": 'Radehiv-1',\n",
    "        \"meteo_source\": 'OpenMeteo',\n",
    "        \"power_max\": 6915,\n",
    "        \"latitude\": 50.288502, \n",
    "        \"longitude\": 24.651951,\n",
    "        \"altitude\": 230,\n",
    "        \"date_train_start\": '2024-04-02',\n",
    "        \"date_train_end\": '2024-09-15'        \n",
    "    },    \n",
    "    {\n",
    "        \"station_name\": 'Boryslav',\n",
    "        \"meteo_source\": 'Copernicus',\n",
    "        \"power_max\": 7153,\n",
    "        \"latitude\": 49.308290,\n",
    "        \"longitude\": 23.430082,\n",
    "        \"altitude\": 350,\n",
    "        \"date_train_start\": '2024-04-02',\n",
    "        \"date_train_end\": '2024-09-15'\n",
    "    },\n",
    "]\n",
    "\n",
    "# +----------------------------------------------------+--------------------+\n",
    "# |                   Навчання                         |       Прогноз      |\n",
    "# +----------------------------------------------------+--------------------+\n",
    "#  2024-04-01                                2024-08-27            2024-09-30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============= Yavoriv 2024-04-02 - 2024-09-15 =============\n",
      "\n",
      "Лінійна регресія:\n",
      "TAE: 52782541.089\n",
      "MAE: 3418.337\n",
      "MAPE(max): 5.771\n",
      "MSE: 42757313.009\n",
      "RMSE: 6538.908\n",
      "RMSE(max): 11.039\n",
      "R2: 0.876\n",
      "MSLE: 0.921\n",
      "Bias: 0.164\n",
      "EV: 0.876\n",
      "PCC: 0.936\n",
      "\n",
      "Розмір навчальної вибірки: 12348\n",
      "Розмір тестової вибірки: 3085\n",
      "Ознаки (19): ['forecast_0', 'gti', 'temperature_air', 'humidity', 'apparent_elevation', 'is_night', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'gti_lag_1', 'gti_lag_2', 'gti_lag_3', 'ghi_lag_1', 'ghi_lag_2', 'ghi_lag_3', 'dni_lag_1', 'dni_lag_2', 'dni_lag_3']\n",
      "LSTM:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_ in models_list:\n",
    "        model_name = f'lstm_{model_[\"station_name\"]}{model_[\"meteo_source\"]}'\n",
    "        data = get_data(\n",
    "                _station_name=model_[\"station_name\"],\n",
    "                _power_max=model_[\"power_max\"],\n",
    "                _date_start=model_[\"date_train_start\"],\n",
    "                _date_end=model_[\"date_train_end\"],\n",
    "                _meteo_source=model_[\"meteo_source\"]\n",
    "                )\n",
    "        _power_max = model_[\"power_max\"]\n",
    "\n",
    "        print(f\"\\n\\n============= {model_['station_name']} {model_['date_train_start']} - {model_['date_train_end']} =============\")\n",
    "\n",
    "        # Додавання ознак\n",
    "        add_features(data,\n",
    "                model_[\"latitude\"], model_[\"longitude\"], model_[\"altitude\"],\n",
    "                _meteo_source=model_[\"meteo_source\"]\n",
    "                )\n",
    "        \n",
    "        # Відображення метрик лінійної регресії\n",
    "        print(f\"\\nЛінійна регресія:\")\n",
    "        evaluate_data(_forecast=data['forecast_0'], _actual=data['power'], _power_max=_power_max, _print_metrics=True)\n",
    "\n",
    "        # Підготовка даних\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        X_train, X_test, y_train, y_test, datetimes_train, datetimes_test = prepare_data(_data=data,\n",
    "                                                                                        _scaler=scaler,\n",
    "                                                                                        _power_max=_power_max,\n",
    "                                                                                        _split_ratio=0.8,\n",
    "                                                                                        use_all_features = False)\n",
    "        print(f\"LSTM:\\n\")\n",
    "\n",
    "        # Створення моделі\n",
    "        model = create_model(X_train)\n",
    "\n",
    "        # Тренування моделі\n",
    "        history_train = do_train(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "        plot_loss(_history=history_train, _title='Криві навчання', _metrics=['loss'])\n",
    "\n",
    "        # Збереження моделі\n",
    "        save_model(model, scaler, model_name)\n",
    "\n",
    "        # Прогнозування\n",
    "        y_train_pred = do_forecast(model, X_train)\n",
    "        y_test_pred = do_forecast(model, X_test)\n",
    "\n",
    "        # Відновлення даних та корекція прогнозу\n",
    "        train_data_forecast = restore_data(_scaler=scaler,_forecast=y_train_pred,_X_test=X_train,_y_test=y_train,_datetimes_test=datetimes_train)\n",
    "        test_data_forecast = restore_data(_scaler=scaler, _forecast=y_test_pred, _X_test=X_test, _y_test=y_test, _datetimes_test=datetimes_test)\n",
    "\n",
    "        plot_residuals(\n",
    "                _y_train_actual=train_data_forecast[\"power\"],\n",
    "                _y_train_forecast=train_data_forecast[\"forecast\"],\n",
    "                _y_test_actual=test_data_forecast[\"power\"],\n",
    "                _y_test_forecast=test_data_forecast[\"forecast\"],\n",
    "                _power_max=_power_max,\n",
    "                _title=f\"Графік залишків для {model_['station_name']} {model_['meteo_source']}\"\n",
    "        )\n",
    "        \n",
    "        plot_residual_histogram(_y_actual=train_data_forecast[\"power\"],\n",
    "                                _y_forecast=train_data_forecast[\"forecast\"],\n",
    "                                _power_max=_power_max,\n",
    "                                _bins=100,\n",
    "                                _title=\"Гістограма залишків навчальних значень\")\n",
    "        \n",
    "        plot_residual_histogram(_y_actual=test_data_forecast[\"power\"],\n",
    "                                _y_forecast=test_data_forecast[\"forecast\"],\n",
    "                                _power_max=_power_max,\n",
    "                                _bins=100,\n",
    "                                _title=\"Гістограма залишків тестових значень\")\n",
    "\n",
    "        \n",
    "        test_data_forecast = correct_forecast(test_data_forecast, data)\n",
    "\n",
    "        # Оцінка прогнозу і візуалізація часовових рядів потужності\n",
    "        model_['metrics'] = evaluate_data(_forecast=test_data_forecast['forecast'], _actual=test_data_forecast['power'], _power_max=_power_max, _print_metrics=True)\n",
    "        plot_series(_data=test_data_forecast,\n",
    "                _columns=  [{\"column\": \"power\", \"label\": \"Факт\", \"power_max\": model_[\"power_max\"]},\n",
    "                                {\"column\": \"forecast\", \"label\": \"Прогноз\", \"power_max\": model_[\"power_max\"]}],\n",
    "                _title=\"Фактична і Прогнозована потужність (LSTM)\",\n",
    "                _metrics=model_['metrics'],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models_list:\n",
    "    model['metrics']['Станція (метеодані)'] = model.get('station_name', 'Unknown') + ' ' + model.get('meteo_source', 'Unknown')\n",
    "\n",
    "# Вибір колонок для виводу\n",
    "selected_columns = [\"Станція (метеодані)\", \"APE\", \"MAPE(max)\", \"RMSE(max)\", \"R2\", \"MSLE\", \"Bias\", \"EV\", \"PCC\"]\n",
    "\n",
    "# Формування даних для таблиці\n",
    "metrics_array = [\n",
    "    {key: model['metrics'][key] for key in selected_columns if key in model['metrics']}\n",
    "    for model in models_list\n",
    "]\n",
    "\n",
    "# Створення таблиці та округлення\n",
    "metrics_table = pd.DataFrame(metrics_array)\n",
    "metrics_table = metrics_table.round(2)\n",
    "metrics_table.set_index('Станція (метеодані)', inplace=True)\n",
    "# metrics_table['Рейтиг'] = metrics_table[['APE', 'MAPE(max)', 'RMSE(max)']].sum(axis=1).rank(ascending=True)\n",
    "# display(metrics_table.sort_values(by='Рейтиг'))\n",
    "\n",
    "# Відображення таблиці\n",
    "display(metrics_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
